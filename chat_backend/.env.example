# Groq API Configuration
# Get your API key from: https://console.groq.com/keys
GROQ_API_KEY=your_groq_api_key_here

# Groq Model Selection
# Available models (Updated December 2025):
# - llama-3.3-70b-versatile (Recommended: Latest, most capable)
# - llama-3.1-8b-instant (Fastest, good for simple forms)
# - mixtral-8x7b-32768 (Good alternative with large context)
# - gemma2-9b-it (Google's efficient model)
#
# Vision models (automatically used when image is uploaded):
# - llama-3.2-90b-vision-preview (Best vision model available)
# - llama-3.2-11b-vision-preview (Faster vision model) - DECOMMISSIONED
#
# Note: Vision models are automatically selected when you upload an image
GROQ_MODEL=llama-3.3-70b-versatile

# Server Configuration
PORT=3000
NODE_ENV=development

# Rate Limiting Configuration
# Time window in seconds for rate limiting
RATE_LIMIT_TTL=60

# Maximum number of requests per TTL window
RATE_LIMIT_MAX=10

# LLM Configuration
# Temperature for AI responses (0.0 - 1.0, lower = more consistent)
LLM_TEMPERATURE=0.3

# Maximum tokens for AI response
LLM_MAX_TOKENS=4000

# Request timeout in milliseconds
LLM_TIMEOUT=30000
